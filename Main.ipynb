{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence\n",
    "import statistics\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import import_ipynb\n",
    "#from Model import net\n",
    "from Dataloader2 import EEGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_pred, y, train_count):\n",
    "    max_values, _ = torch.max(y_pred, dim=1, keepdim=True)\n",
    "    mask = y_pred == max_values\n",
    "    y_pred = mask.int()\n",
    "    correct_num = torch.sum(torch.all(torch.eq(y, y_pred), dim=1)).item()\n",
    "    accuracy = correct_num / train_count\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_path, test_class, verbose=True):\n",
    "    \n",
    "\n",
    "    x_test = mne.read_epochs(test_path, preload=False).get_data(picks='eeg');\n",
    "    normals = []\n",
    "    scaler = StandardScaler()\n",
    "    for idx in range(len(x_test)):\n",
    "        normals.append(scaler.fit_transform(x_test[idx]))\n",
    "    normals = torch.tensor(normals).cuda().float()\n",
    "    result = torch.argmax(model(normals), axis=1)\n",
    "    unique_elements, counts = torch.unique(result, return_counts=True)\n",
    "\n",
    "    votes = np.zeros([4])\n",
    "    for i in range(len(unique_elements)):\n",
    "        votes[unique_elements[i]] = counts[i]\n",
    "\n",
    "\n",
    "    if(verbose):\n",
    "        print(f\"Test Accuracy: {(votes[test_class] / result.shape[0]) * 100}\")\n",
    "    return votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, T, C, input_size, hidden_size, num_layers, spatial_num, dropout, pool):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.spatial_num = spatial_num\n",
    "        self.dropout = dropout\n",
    "        self.pool = pool\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.cell_count = self.T // self.input_size\n",
    "\n",
    "        self.fcn_in = (spatial_num * self.hidden_size)\n",
    "\n",
    "        self._lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "\n",
    "        self.lstm = nn.ModuleList([self._lstm for i in range(self.C)])\n",
    "\n",
    "        self.cnn_block = nn.Sequential(nn.Conv2d(1, self.spatial_num, (self.C, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "\n",
    "\n",
    "                                       nn.Dropout(self.dropout))\n",
    "\n",
    "        \n",
    "        self.fcn = nn.Sequential(nn.Linear(self.fcn_in, 128), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 16),\n",
    "                                 nn.Dropout(self.dropout),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(16, 4))\n",
    "\n",
    "        #self.fcn = nn.Linear(self.fcn_in, 4)\n",
    "        self.results = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, 19, 3000)\n",
    "        self.N = x.shape[0]\n",
    "        x = x.reshape(self.N, self.C, self.cell_count, self.input_size)\n",
    "        _x = None\n",
    "\n",
    "        for index, cell in enumerate(self.lstm):\n",
    "            cell_out, _ = cell(x[:, index, :, :], None)\n",
    "            last_layer_out = cell_out[:, -1, :]\n",
    "            \n",
    "            last_layer_out = last_layer_out.unsqueeze(0)\n",
    "            if _x is None:\n",
    "                _x = last_layer_out\n",
    "            else:\n",
    "                _x = torch.cat((_x, last_layer_out), dim=0)\n",
    "            \n",
    "\n",
    "        x = _x.permute(1, 0, 2).unsqueeze(1)\n",
    "\n",
    "        x = self.cnn_block(x)\n",
    "\n",
    "\n",
    "        x = x.reshape(self.N, -1)\n",
    "\n",
    "        x = self.fcn(x)\n",
    "        x = self.results(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNE_Data = EEGDataset(root_dir=r\"C:\\Users\\admin\\Desktop\\MNE Data\")\n",
    "#MNE_Data = EEGDataset(root_dir=r\"D:\\TEST MNE\")\n",
    "test_path = r\"C:\\Users\\admin\\Desktop\\TEST\\amirifateme.fif\"\n",
    "test_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_dataloader = DataLoader(MNE_Data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(T = 3000, C = 19, input_size = 300, hidden_size = 100, num_layers=1, spatial_num= 30, dropout=0.5, pool=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight = torch.Tensor([5.3125, 2.8333, 3.5417, 5.6667]).cuda())\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [00:46<1:01:30, 46.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 29.346092503987244\n",
      "mean train accuracy across epoch: 29.777560828869706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [01:34<1:01:25, 47.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 23.923444976076556\n",
      "mean train accuracy across epoch: 28.29943812061339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [02:21<1:00:46, 47.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 38.75598086124402\n",
      "mean train accuracy across epoch: 28.364200325229696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [03:11<1:01:06, 48.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 23.923444976076556\n",
      "mean train accuracy across epoch: 28.53071286655868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/80 [04:19<1:09:13, 55.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 21.371610845295056\n",
      "mean train accuracy across epoch: 28.820400253078013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [05:07<1:05:21, 53.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 56.45933014354066\n",
      "mean train accuracy across epoch: 29.42675819513106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/80 [05:54<1:01:58, 50.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 19.457735247208934\n",
      "mean train accuracy across epoch: 29.903306562151194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [06:41<59:38, 49.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 30.303030303030305\n",
      "mean train accuracy across epoch: 30.774760677836678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/80 [07:28<57:48, 48.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 24.720893141945773\n",
      "mean train accuracy across epoch: 31.663214606278537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [08:15<56:15, 48.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 13.237639553429027\n",
      "mean train accuracy across epoch: 32.31637047306193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [09:01<54:52, 47.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 13.716108452950559\n",
      "mean train accuracy across epoch: 33.25371741424269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [09:48<53:37, 47.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 17.384370015948964\n",
      "mean train accuracy across epoch: 34.23390466551838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [10:45<56:10, 50.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 8.293460925039872\n",
      "mean train accuracy across epoch: 35.27303946737012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/80 [11:32<54:05, 49.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 8.771929824561402\n",
      "mean train accuracy across epoch: 36.430282166004744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/80 [12:19<52:34, 48.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 15.47049441786284\n",
      "mean train accuracy across epoch: 37.38801851301276\n"
     ]
    }
   ],
   "source": [
    "test_log = []\n",
    "log = []\n",
    "for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_num = 0\n",
    "        \n",
    "        \n",
    "\n",
    "        for index, data in enumerate(train_dataloader):\n",
    "            \n",
    "            x, y = data\n",
    "            y = y.to(torch.float64)\n",
    "            x = x.reshape(-1, 1, 19, 3000).float()\n",
    "            x = x[torch.randperm(x.shape[0])]\n",
    "            y = F.one_hot(torch.tensor(torch.tensor([y.item()]).to(torch.int64)), num_classes=4).expand(x.shape[0], -1).float()\n",
    "            \n",
    "            train_count = x.shape[0]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            log.append(Accuracy(y_pred, y, train_count))\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        votes = test(model, test_path, test_class)\n",
    "        test_log.append(votes)\n",
    "        print(f\"mean train accuracy across epoch: {statistics.mean(log)}\")\n",
    "        \n",
    "        #print(f\"Train Accuracy:{correct_num / train_count}\")\n",
    "        \"\"\"\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46808511, 0.39209726, 0.10030395, 0.03951368])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_log = np.array(test_log)\n",
    "test_log[np.argmax(test_log[:, 0])] / test_log[np.argmax(test_log[:, 0])].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 192., 123.,  14.],\n",
       "       [  0.,  99., 179.,  51.],\n",
       "       [  0., 129., 134.,  66.],\n",
       "       [ 26.,  97., 152.,  54.],\n",
       "       [  4., 146., 133.,  46.],\n",
       "       [109.,  87., 107.,  26.],\n",
       "       [ 78., 119., 103.,  29.],\n",
       "       [ 33.,  79., 113., 104.],\n",
       "       [112.,  99.,  84.,  34.],\n",
       "       [ 73., 113.,  57.,  86.],\n",
       "       [ 58., 129.,  67.,  75.],\n",
       "       [ 49., 128.,  71.,  81.],\n",
       "       [104., 151.,  30.,  44.],\n",
       "       [ 81., 206.,  23.,  19.],\n",
       "       [ 73., 208.,  42.,   6.],\n",
       "       [ 73., 143.,  14.,  99.],\n",
       "       [ 43., 195.,  69.,  22.],\n",
       "       [ 63., 214.,  33.,  19.],\n",
       "       [ 83., 221.,  22.,   3.],\n",
       "       [154., 129.,  33.,  13.],\n",
       "       [104., 154.,  33.,  38.],\n",
       "       [ 69., 225.,  30.,   5.],\n",
       "       [104., 184.,  33.,   8.],\n",
       "       [ 93., 145.,  56.,  35.],\n",
       "       [ 73., 197.,  55.,   4.],\n",
       "       [ 74., 147.,  81.,  27.],\n",
       "       [ 26., 175., 118.,  10.],\n",
       "       [ 61., 219.,  43.,   6.],\n",
       "       [ 59., 162., 102.,   6.],\n",
       "       [ 54., 219.,  46.,  10.],\n",
       "       [ 47., 208.,  61.,  13.],\n",
       "       [ 11., 202., 113.,   3.],\n",
       "       [  9., 265.,  55.,   0.],\n",
       "       [ 24., 200., 100.,   5.],\n",
       "       [ 22., 201.,  96.,  10.],\n",
       "       [ 11., 199., 105.,  14.],\n",
       "       [ 12., 255.,  57.,   5.],\n",
       "       [ 18., 196., 103.,  12.],\n",
       "       [  4., 238.,  86.,   1.],\n",
       "       [  3., 263.,  61.,   2.],\n",
       "       [ 14., 212.,  89.,  14.],\n",
       "       [  0., 279.,  50.,   0.],\n",
       "       [  1., 268.,  56.,   4.],\n",
       "       [  8., 197.,  96.,  28.],\n",
       "       [  1., 268.,  59.,   1.],\n",
       "       [  0., 242.,  86.,   1.],\n",
       "       [  3., 225.,  93.,   8.],\n",
       "       [ 10., 243.,  75.,   1.],\n",
       "       [  1., 279.,  49.,   0.],\n",
       "       [  0., 295.,  34.,   0.],\n",
       "       [  2., 270.,  57.,   0.],\n",
       "       [  1., 249.,  77.,   2.],\n",
       "       [  0., 248.,  75.,   6.],\n",
       "       [  0., 270.,  58.,   1.],\n",
       "       [  6., 248.,  68.,   7.],\n",
       "       [  0., 261.,  66.,   2.],\n",
       "       [  0., 280.,  48.,   1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in trange(epochs):\\n        model.train()\\n        running_loss = 0.0\\n        correct_num = 0\\n        log = []\\n        for index, data in enumerate(train_dataloader):\\n            \\n            x, y = data\\n            y = y.to(torch.float64)\\n            print(y)\\n            \\n            x = x.reshape(-1, 1, 19, 3000).float()\\n            y = torch.tensor([y.item()]).to(torch.int64).expand(x.shape[0], -1).float()\\n            \\n            \\n            train_count = x.shape[0]\\n            x, y = x.to(device), y.to(device)\\n            y_pred = model(x)\\n            loss = criterion(y_pred, y)\\n            optimizer.zero_grad()\\n            loss.backward()\\n            optimizer.step()\\n            scheduler.step()\\n            print(y[-1])\\n            print(Accuracy(y_pred, y, train_count))\\n            log.append(Accuracy(y_pred, y, train_count))\\n            torch.cuda.empty_cache()\\n            \\n        \\n        '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_num = 0\n",
    "        log = []\n",
    "        for index, data in enumerate(train_dataloader):\n",
    "            \n",
    "            x, y = data\n",
    "            y = y.to(torch.float64)\n",
    "            print(y)\n",
    "            \n",
    "            x = x.reshape(-1, 1, 19, 3000).float()\n",
    "            y = torch.tensor([y.item()]).to(torch.int64).expand(x.shape[0], -1).float()\n",
    "            \n",
    "            \n",
    "            train_count = x.shape[0]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            print(y[-1])\n",
    "            print(Accuracy(y_pred, y, train_count))\n",
    "            log.append(Accuracy(y_pred, y, train_count))\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        #print(f\"mean accuracy across epoch: {statistics.mean(log)}\")\n",
    "        \n",
    "        #print(f\"Train Accuracy:{correct_num / train_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'D:\\model weights\\model_weights.pth'\n",
    "torch.save(model.state_dict(), file_path)\n",
    "model.load_state_dict(torch.load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny = F.one_hot(torch.randint(low=0, high=4, size=(1,)), 4).float()\\nyhat = torch.rand((1, 4)).float()\\ncriterion(y, yhat)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "y = F.one_hot(torch.randint(low=0, high=4, size=(1,)), 4).float()\n",
    "yhat = torch.rand((1, 4)).float()\n",
    "criterion(y, yhat)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n__ = (torch.round(y_pred).to(torch.int64) == y)\\npreds = np.all(__.cpu().numpy(), axis=1)\\ncorrect_num += np.count_nonzero(preds)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "__ = (torch.round(y_pred).to(torch.int64) == y)\n",
    "preds = np.all(__.cpu().numpy(), axis=1)\n",
    "correct_num += np.count_nonzero(preds)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
