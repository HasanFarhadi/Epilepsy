{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence\n",
    "import statistics\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import import_ipynb\n",
    "#from Model import net\n",
    "from Dataloader2 import EEGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_pred, y, train_count):\n",
    "    max_values, _ = torch.max(y_pred, dim=1, keepdim=True)\n",
    "    mask = y_pred == max_values\n",
    "    y_pred = mask.int()\n",
    "    correct_num = torch.sum(torch.all(torch.eq(y, y_pred), dim=1)).item()\n",
    "    accuracy = correct_num / train_count\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_path, test_class, verbose=True):\n",
    "    \n",
    "\n",
    "    x_test = mne.read_epochs(test_path, preload=False).get_data(picks='eeg');\n",
    "    normals = []\n",
    "    scaler = StandardScaler()\n",
    "    for idx in range(len(x_test)):\n",
    "        normals.append(scaler.fit_transform(x_test[idx]))\n",
    "    normals = torch.tensor(normals).cuda().float()\n",
    "    result = torch.argmax(model(normals), axis=1)\n",
    "    unique_elements, counts = torch.unique(result, return_counts=True)\n",
    "\n",
    "    votes = np.zeros([4])\n",
    "    for i in range(len(unique_elements)):\n",
    "        votes[unique_elements[i]] = counts[i]\n",
    "\n",
    "\n",
    "    if(verbose):\n",
    "        print(f\"Test Accuracy: {(votes[test_class] / result.shape[0]) * 100}\")\n",
    "    return votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, T, C, input_size, hidden_size, num_layers, spatial_num, dropout, pool):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.spatial_num = spatial_num\n",
    "        self.dropout = dropout\n",
    "        self.pool = pool\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.cell_count = self.T // self.input_size\n",
    "\n",
    "        self.fcn_in = (spatial_num * self.hidden_size)\n",
    "\n",
    "        self._lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "\n",
    "        self.lstm = nn.ModuleList([self._lstm for i in range(self.C)])\n",
    "\n",
    "        self.cnn_block = nn.Sequential(nn.Conv2d(1, self.spatial_num, (self.C, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "\n",
    "\n",
    "                                       nn.Dropout(self.dropout))\n",
    "\n",
    "        \n",
    "        self.fcn = nn.Sequential(nn.Linear(self.fcn_in, 128), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 16),\n",
    "                                 nn.Dropout(self.dropout),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(16, 4))\n",
    "\n",
    "        #self.fcn = nn.Linear(self.fcn_in, 4)\n",
    "        self.results = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, 19, 3000)\n",
    "        self.N = x.shape[0]\n",
    "        x = x.reshape(self.N, self.C, self.cell_count, self.input_size)\n",
    "        _x = None\n",
    "\n",
    "        for index, cell in enumerate(self.lstm):\n",
    "            cell_out, _ = cell(x[:, index, :, :], None)\n",
    "            last_layer_out = cell_out[:, -1, :]\n",
    "            \n",
    "            last_layer_out = last_layer_out.unsqueeze(0)\n",
    "            if _x is None:\n",
    "                _x = last_layer_out\n",
    "            else:\n",
    "                _x = torch.cat((_x, last_layer_out), dim=0)\n",
    "            \n",
    "\n",
    "        x = _x.permute(1, 0, 2).unsqueeze(1)\n",
    "\n",
    "        x = self.cnn_block(x)\n",
    "\n",
    "\n",
    "        x = x.reshape(self.N, -1)\n",
    "\n",
    "        x = self.fcn(x)\n",
    "        x = self.results(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size =hidden_size\n",
    "        self.dropout = 0.5\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv1d(19, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(3000, self.hidden_size, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(nn.Linear(self.hidden_size * 128, 128), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 16),\n",
    "                                 nn.Dropout(self.dropout),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(16, self.num_classes))\n",
    "        \n",
    "\n",
    "        self.results = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 19, 3000)\n",
    "        self.N = x.shape[0]\n",
    "        # Apply CNN\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = self.pool(x)\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        # Reshape for LSTM\n",
    "        \n",
    "        #x = x.transpose(1, 2)\n",
    "        \n",
    "        # Apply LSTM\n",
    "        h_n, (__, _) = self.lstm(x)\n",
    "\n",
    "        x = h_n[:, :, :]\n",
    "        xx = x\n",
    "        # Apply fully connected layer\n",
    "        x = x.reshape(self.N, -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.results(x)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNE_Data = EEGDataset(root_dir=r\"C:\\Users\\admin\\Desktop\\MNE Data\")\n",
    "labels = MNE_Data.labels\n",
    "#MNE_Data = EEGDataset(root_dir=r\"D:\\TEST MNE\")\n",
    "test_path = r\"C:\\Users\\admin\\Desktop\\TEST\\amirifateme.fif\"\n",
    "test_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(MNE_Data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2914228\n"
     ]
    }
   ],
   "source": [
    "#model = net(T = 3000, C = 19, input_size = 3000, hidden_size = 100, num_layers=2, spatial_num= 300, dropout=0.5, pool=1).to(device)\n",
    "model = CNN_LSTM(num_classes=4, hidden_size=100).cuda()\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Number of parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight = torch.Tensor([6.3125, 2.8333, 2.5417, 6.6667]).cuda())\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "epochs = 30\n",
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_indices, val_indices in kf.split(MNE_Data, labels):\n",
    "    train_dataset = torch.utils.data.Subset(MNE_Data, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(MNE_Data, val_indices)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    test_log = []\n",
    "    log = []\n",
    "\n",
    "    for epoch in trange(epochs):\n",
    "\n",
    "        model.train()   \n",
    "        for index, data in enumerate(train_dataloader):\n",
    "                \n",
    "                x, y = data\n",
    "                y = y.to(torch.float64)\n",
    "                x = x.reshape(-1, 1, 19, 3000).float()\n",
    "                x = x[torch.randperm(x.shape[0])]\n",
    "                y = F.one_hot(torch.tensor(torch.tensor([y.item()]).to(torch.int64)), num_classes=4).expand(x.shape[0], -1).float()\n",
    "                \n",
    "                train_count = x.shape[0]\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_log = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_dataloader):\n",
    "                        data = data.reshape(-1, 1, 19, 3000).float().cuda()\n",
    "                        target = F.one_hot(torch.tensor(torch.tensor([target.item()]).to(torch.int64)), num_classes=4).expand(data.shape[0], -1).float().cuda()\n",
    "                        \n",
    "\n",
    "                        output = model(data)\n",
    "\n",
    "                        \n",
    "\n",
    "                        loss = criterion(output, target)\n",
    "                        \n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                        val_log.append(Accuracy(output, target, target.shape[0]))\n",
    "\n",
    "                        \n",
    "        print('Epoch: {}, Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'.format(\n",
    "                    epoch, val_loss / len(val_dataloader), statistics.mean(val_log)))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.07177033492823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 74., 408.,   0., 145.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_path=r\"C:\\Users\\admin\\Desktop\\TEST\\amirifateme.fif\", model=model, test_class= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'D:\\model weights\\model_weights.pth'\n",
    "torch.save(model.state_dict(), file_path)\n",
    "model.load_state_dict(torch.load(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
