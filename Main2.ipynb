{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence\n",
    "import statistics\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Dataloader2.ipynb\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import import_ipynb\n",
    "#from Model import net\n",
    "from Dataloader2 import EEGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_pred, y, train_count):\n",
    "    max_values, _ = torch.max(y_pred, dim=1, keepdim=True)\n",
    "    mask = y_pred == max_values\n",
    "    y_pred = mask.int()\n",
    "    correct_num = torch.sum(torch.all(torch.eq(y, y_pred), dim=1)).item()\n",
    "    accuracy = correct_num / train_count\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_path, test_class, verbose=True):\n",
    "    \n",
    "\n",
    "    x_test = mne.read_epochs(test_path, preload=False).get_data(picks='eeg');\n",
    "    normals = []\n",
    "    scaler = StandardScaler()\n",
    "    for idx in range(len(x_test)):\n",
    "        normals.append(scaler.fit_transform(x_test[idx]))\n",
    "    normals = torch.tensor(normals).cuda().float()\n",
    "    out = model(normals)\n",
    "    result = torch.argmax(out, axis=1)\n",
    "    unique_elements, counts = torch.unique(result, return_counts=True)\n",
    "\n",
    "    votes = np.zeros([4])\n",
    "    for i in range(len(unique_elements)):\n",
    "        votes[unique_elements[i]] = counts[i]\n",
    "\n",
    "\n",
    "    if(verbose):\n",
    "        print(f\"Test Accuracy: {(votes[test_class] / result.shape[0]) * 100}\")\n",
    "    return votes, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, T, C, input_size, hidden_size, num_layers, spatial_num, dropout, pool):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.spatial_num = spatial_num\n",
    "        self.dropout = dropout\n",
    "        self.pool = pool\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.cell_count = self.T // self.input_size\n",
    "\n",
    "        self.fcn_in = (spatial_num * self.hidden_size)\n",
    "\n",
    "        self._lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "\n",
    "        self.lstm = nn.ModuleList([self._lstm for i in range(self.C)])\n",
    "\n",
    "        self.cnn_block = nn.Sequential(nn.Conv2d(1, self.spatial_num, (self.C, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "\n",
    "\n",
    "                                       nn.Dropout(self.dropout))\n",
    "\n",
    "        \n",
    "        self.fcn = nn.Sequential(nn.Linear(self.fcn_in, 128), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 16),\n",
    "                                 nn.Dropout(self.dropout),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(16, 4))\n",
    "\n",
    "        #self.fcn = nn.Linear(self.fcn_in, 4)\n",
    "        self.results = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, 19, 3000)\n",
    "        self.N = x.shape[0]\n",
    "        x = x.reshape(self.N, self.C, self.cell_count, self.input_size)\n",
    "        _x = None\n",
    "\n",
    "        for index, cell in enumerate(self.lstm):\n",
    "            cell_out, _ = cell(x[:, index, :, :], None)\n",
    "            last_layer_out = cell_out[:, -1, :]\n",
    "            \n",
    "            last_layer_out = last_layer_out.unsqueeze(0)\n",
    "            if _x is None:\n",
    "                _x = last_layer_out\n",
    "            else:\n",
    "                _x = torch.cat((_x, last_layer_out), dim=0)\n",
    "            \n",
    "\n",
    "        x = _x.permute(1, 0, 2).unsqueeze(1)\n",
    "\n",
    "        x = self.cnn_block(x)\n",
    "\n",
    "\n",
    "        x = x.reshape(self.N, -1)\n",
    "\n",
    "        x = self.fcn(x)\n",
    "        x = self.results(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size =hidden_size\n",
    "        self.dropout = 0.5\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(19, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(4, 1, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(3000, self.hidden_size, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(nn.Linear(self.hidden_size , 16),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(16, self.num_classes))\n",
    "        \n",
    "\n",
    "        self.results = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 19, 3000)\n",
    "        self.N = x.shape[0]\n",
    "\n",
    "        x = x.reshape(-1, 19, 1, 3000)\n",
    "        # Apply CNN\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = self.pool(x)\n",
    "        xx = x\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        # Reshape for LSTM\n",
    "        \n",
    "        #x = x.transpose(1, 2)\n",
    "        \n",
    "        # Apply LSTM\n",
    "        \n",
    "        x = x.reshape(-1, 1, 3000)\n",
    "        \n",
    "        h_n, (__, _) = self.lstm(x)\n",
    "\n",
    "        x = h_n[:, :, :]\n",
    "        \n",
    "        \n",
    "        # Apply fully connected layer\n",
    "        x = x.reshape(self.N, -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.results(x)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return x\n",
    "    \n",
    "model = CNN_LSTM(num_classes=4, hidden_size=100).cuda()\n",
    "model(torch.rand(7, 19, 3000).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNE_Data = EEGDataset(root_dir=r\"C:\\Users\\admin\\Desktop\\TEST\")\n",
    "labels = MNE_Data.labels\n",
    "#MNE_Data = EEGDataset(root_dir=r\"D:\\TEST MNE\")\n",
    "test_path = r\"C:\\Users\\admin\\Desktop\\TEST\\amirifateme.fif\"\n",
    "test_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(MNE_Data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1244189\n"
     ]
    }
   ],
   "source": [
    "config = net(T = 3000, C = 19, input_size = 3000, hidden_size = 30, num_layers=1, spatial_num= 300, dropout=0.5, pool=1).to(device)\n",
    "#config = CNN_LSTM(num_classes=4, hidden_size=30).cuda()\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Number of parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss(weight = torch.Tensor([5.3125, 1.8333, 3.5417, 6.6667]).cuda())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "epochs = 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:09<00:36,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0\n",
      "[  0.   0. 371.   0.]\n",
      "Epoch: 0, Validation Loss: 1.3920, Validation Accuracy: 20.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:18<00:27,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 12.93800539083558\n",
      "[  0.  48. 323.   0.]\n",
      "Epoch: 1, Validation Loss: 1.3539, Validation Accuracy: 35.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:27<00:18,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 44.20485175202156\n",
      "[ 52. 164. 155.   0.]\n",
      "Epoch: 2, Validation Loss: 1.2036, Validation Accuracy: 59.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:36<00:09,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.51482479784366\n",
      "[ 20. 295.  56.   0.]\n",
      "Epoch: 3, Validation Loss: 1.0672, Validation Accuracy: 71.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:45<00:00,  9.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.68733153638814\n",
      "[  0. 355.  16.   0.]\n",
      "Epoch: 4, Validation Loss: 1.0041, Validation Accuracy: 74.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:08<00:35,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.92183288409704\n",
      "[  0. 367.   3.   1.]\n",
      "Epoch: 0, Validation Loss: 1.3688, Validation Accuracy: 32.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:18<00:27,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 56.334231805929925\n",
      "[130. 209.  31.   1.]\n",
      "Epoch: 1, Validation Loss: 1.3013, Validation Accuracy: 52.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:27<00:18,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 24.528301886792452\n",
      "[ 28.  91.  11. 241.]\n",
      "Epoch: 2, Validation Loss: 1.1981, Validation Accuracy: 57.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:36<00:09,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 40.16172506738545\n",
      "[ 87. 149.  17. 118.]\n",
      "Epoch: 3, Validation Loss: 1.1364, Validation Accuracy: 61.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:45<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 54.98652291105122\n",
      "[ 25. 204.  17. 125.]\n",
      "Epoch: 4, Validation Loss: 1.1018, Validation Accuracy: 66.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:09<00:36,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 58.490566037735846\n",
      "[  0. 217. 154.   0.]\n",
      "Epoch: 0, Validation Loss: 1.3782, Validation Accuracy: 34.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:18<00:27,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.078167115902965\n",
      "[  3.   4. 364.   0.]\n",
      "Epoch: 1, Validation Loss: 1.3753, Validation Accuracy: 32.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:27<00:18,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.6172506738544474\n",
      "[ 12.   6. 144. 209.]\n",
      "Epoch: 2, Validation Loss: 1.2705, Validation Accuracy: 57.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:36<00:09,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 12.398921832884097\n",
      "[  2.  46. 255.  68.]\n",
      "Epoch: 3, Validation Loss: 1.1690, Validation Accuracy: 61.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:45<00:00,  9.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 17.52021563342318\n",
      "[  7.  65.  75. 224.]\n",
      "Epoch: 4, Validation Loss: 1.0352, Validation Accuracy: 71.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:09<00:36,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0\n",
      "[  0.   0. 371.   0.]\n",
      "Epoch: 0, Validation Loss: 1.3797, Validation Accuracy: 25.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:17<00:26,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0\n",
      "[ 40.   0. 328.   3.]\n",
      "Epoch: 1, Validation Loss: 1.3430, Validation Accuracy: 41.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:27<00:18,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 2.15633423180593\n",
      "[107.   8. 175.  81.]\n",
      "Epoch: 2, Validation Loss: 1.2197, Validation Accuracy: 63.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:36<00:09,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 5.929919137466308\n",
      "[ 17.  22. 210. 122.]\n",
      "Epoch: 3, Validation Loss: 1.0841, Validation Accuracy: 68.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:45<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 6.199460916442049\n",
      "[137.  23.  51. 160.]\n",
      "Epoch: 4, Validation Loss: 0.9982, Validation Accuracy: 70.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:09<00:36,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0\n",
      "[  0.   0. 371.   0.]\n",
      "Epoch: 0, Validation Loss: 1.3816, Validation Accuracy: 25.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:18<00:27,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2695417789757413\n",
      "[ 18.   1. 352.   0.]\n",
      "Epoch: 1, Validation Loss: 1.3355, Validation Accuracy: 47.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:27<00:17,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0\n",
      "[  7.   0. 210. 154.]\n",
      "Epoch: 2, Validation Loss: 1.2339, Validation Accuracy: 53.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:36<00:24, 12.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15680\\2047201332.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\admin\\Desktop\\TEST\\IGE\\borzoimohamad.fif\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_class\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         print('Epoch: {}, Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'.format(\n\u001b[0;32m     60\u001b[0m                     epoch, val_loss / len(val_dataloader), statistics.mean(val_log)))\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15680\\2625896039.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, test_path, test_class, verbose)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mnormals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mnormals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_indices, val_indices in kf.split(MNE_Data, labels):\n",
    "    train_dataset = torch.utils.data.Subset(MNE_Data, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(MNE_Data, val_indices)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    test_log = []\n",
    "    log = []\n",
    "\n",
    "\n",
    "    model = deepcopy(config)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in trange(epochs):\n",
    "        \n",
    "        model.train()   \n",
    "        for index, data in enumerate(train_dataloader):\n",
    "                \n",
    "                x, y = data\n",
    "                y = y.to(torch.float64)\n",
    "                x = x.reshape(-1, 1, 19, 3000).float()\n",
    "                x = x[torch.randperm(x.shape[0])]\n",
    "                y = F.one_hot(torch.tensor(torch.tensor([y.item()]).to(torch.int64)), num_classes=4).expand(x.shape[0], -1).float()\n",
    "                \n",
    "                train_count = x.shape[0]\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_log = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_dataloader):\n",
    "                        data = data.reshape(-1, 1, 19, 3000).float().cuda()\n",
    "                        target = F.one_hot(torch.tensor(torch.tensor([target.item()]).to(torch.int64)), num_classes=4).expand(data.shape[0], -1).float().cuda()\n",
    "                        \n",
    "\n",
    "                        output = model(data)\n",
    "\n",
    "                        \n",
    "\n",
    "                        loss = criterion(output, target)\n",
    "                        \n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                        val_log.append(Accuracy(output, target, target.shape[0]))\n",
    "\n",
    "\n",
    "        print(test(test_path=r\"C:\\Users\\admin\\Desktop\\TEST\\IGE\\borzoimohamad.fif\", model=model, test_class= 1)[0])     \n",
    "        print('Epoch: {}, Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'.format(\n",
    "                    epoch, val_loss / len(val_dataloader), statistics.mean(val_log)))\n",
    "\n",
    "    model_list.append(model)\n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File does not exist: \"C:\\Users\\admin\\Desktop\\TEST\\FOCAL\\zahmatbin.fif\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15060\\1533264211.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\admin\\Desktop\\TEST\\FOCAL\\zahmatbin.fif\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_class\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15060\\2625896039.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, test_path, test_class, verbose)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpicks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'eeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mnormals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-206>\u001b[0m in \u001b[0;36mread_epochs\u001b[1;34m(fname, proj, preload, verbose)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\mne\\epochs.py\u001b[0m in \u001b[0;36mread_epochs\u001b[1;34m(fname, proj, preload, verbose)\u001b[0m\n\u001b[0;32m   3868\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3869\u001b[0m     \"\"\"\n\u001b[1;32m-> 3870\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mEpochsFIF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-207>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fname, proj, preload, verbose)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\mne\\epochs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fname, proj, preload, verbose)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mendings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-epo.fif\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-epo.fif.gz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_epo.fif\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_epo.fif.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             )\n\u001b[1;32m-> 3921\u001b[1;33m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_check_fname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmust_exist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpreload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"preload must be used with file-like objects\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-0>\u001b[0m in \u001b[0;36m_check_fname\u001b[1;34m(fname, overwrite, must_exist, name, need_dir, verbose)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\mne\\utils\\check.py\u001b[0m in \u001b[0;36m_check_fname\u001b[1;34m(fname, overwrite, must_exist, name, need_dir, verbose)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mPermissionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{name} does not have read permissions: {fname}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmust_exist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{name} does not exist: \"{fname}\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File does not exist: \"C:\\Users\\admin\\Desktop\\TEST\\FOCAL\\zahmatbin.fif\""
     ]
    }
   ],
   "source": [
    "test_model = model_list[0]\n",
    "test(test_path=r\"C:\\Users\\admin\\Desktop\\TEST\\FOCAL\\zahmatbin.fif\", model=test_model, test_class= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstate_dict = model.state_dict()\\navg_state_dict = state_dict\\nfor key in state_dict:\\n    avg_state_dict[key] += state_dict[key]\\n    print(state_dict[key].shape)\\n    print('lol')\\n    \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "state_dict = model.state_dict()\n",
    "avg_state_dict = state_dict\n",
    "for key in state_dict:\n",
    "    avg_state_dict[key] += state_dict[key]\n",
    "    print(state_dict[key].shape)\n",
    "    print('lol')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.24148606811146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 31.,  98., 102., 415.]),\n",
       " tensor([[9.7044e-02, 1.1328e-01, 5.9685e-01, 1.9282e-01],\n",
       "         [0.0000e+00, 3.6804e-05, 9.9996e-01, 0.0000e+00],\n",
       "         [6.6734e-09, 5.0269e-05, 3.5220e-07, 9.9995e-01],\n",
       "         ...,\n",
       "         [1.1395e-08, 1.0000e+00, 4.5547e-15, 9.1151e-08],\n",
       "         [5.0779e-24, 1.5617e-19, 2.1672e-22, 1.0000e+00],\n",
       "         [3.8696e-09, 1.0000e+00, 1.7858e-13, 4.0086e-14]], device='cuda:0',\n",
       "        grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_path=r\"C:\\Users\\admin\\Desktop\\TEST\\TLE\\KhoshabiMohammad.fif\", model=model_list[1], test_class= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'D:\\model weights\\model_weights.pth'\n",
    "torch.save(model.state_dict(), file_path)\n",
    "model.load_state_dict(torch.load(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
