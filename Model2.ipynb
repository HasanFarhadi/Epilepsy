{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_pred, y, train_count):\n",
    "    max_values, _ = torch.max(y_pred, dim=1, keepdim=True)\n",
    "    mask = y_pred == max_values\n",
    "    y_pred = mask.int()\n",
    "    correct_num = torch.sum(torch.all(torch.eq(y, y_pred), dim=1)).item()\n",
    "    accuracy = correct_num / train_count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.transforms = transforms.ToTensor()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index, ...]\n",
    "        y = self.y[index, ...]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(data):\n",
    "    normals = []\n",
    "    scaler = StandardScaler()\n",
    "    for idx in range(len(data)):\n",
    "        normals.append(scaler.fit_transform(data[idx]))\n",
    "    return np.array(normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPNES_data = mne.read_epochs(r\"D:\\\\MNE Data\\\\PNES\\\\RostamiAlireza.fif\", preload=False).get_data(picks=\\'eeg\\');\\nTLE_data = mne.read_epochs(r\"D:\\\\MNE Data\\\\TLE\\\\AlipoorMohamadHakim.fif\", preload=False).get_data(picks=\\'eeg\\');\\n\\nPNES_data = torch.Tensor(Normalize(PNES_data)).cuda()\\nTLE_data = torch.Tensor(Normalize(TLE_data)).cuda()\\n\\nPNES_labels = torch.Tensor(np.zeros((PNES_data.shape[0]))).cuda()\\nTLE_labels = torch.Tensor(np.ones((TLE_data.shape[0]))).cuda()\\n\\ndata = torch.cat((PNES_data, TLE_data), axis=0).reshape(-1, 1, 19, 3000)\\nlabels = torch.cat((PNES_labels, TLE_labels))\\nlabels = F.one_hot(labels.to(torch.int64))\\n\\nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PNES_data = mne.read_epochs(r\"D:\\MNE Data\\PNES\\RostamiAlireza.fif\", preload=False).get_data(picks='eeg');\n",
    "TLE_data = mne.read_epochs(r\"D:\\MNE Data\\TLE\\AlipoorMohamadHakim.fif\", preload=False).get_data(picks='eeg');\n",
    "\n",
    "PNES_data = torch.Tensor(Normalize(PNES_data)).cuda()\n",
    "TLE_data = torch.Tensor(Normalize(TLE_data)).cuda()\n",
    "\n",
    "PNES_labels = torch.Tensor(np.zeros((PNES_data.shape[0]))).cuda()\n",
    "TLE_labels = torch.Tensor(np.ones((TLE_data.shape[0]))).cuda()\n",
    "\n",
    "data = torch.cat((PNES_data, TLE_data), axis=0).reshape(-1, 1, 19, 3000)\n",
    "labels = torch.cat((PNES_labels, TLE_labels))\n",
    "labels = F.one_hot(labels.to(torch.int64))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "PNES_data = torch.rand([693, 19, 3000])\n",
    "TLE_data = torch.rand([693, 19, 3000])\n",
    "IGE_data = torch.rand([693, 19, 3000])\n",
    "Focal_data = torch.rand([693, 19, 3000])\n",
    "PNES_labels = torch.ones([693]) * 2\n",
    "TLE_labels = torch.ones([693]) * 3\n",
    "IGE_labels = torch.ones([693])\n",
    "Focal_labels = torch.ones([693]) * 0\n",
    "\n",
    "data = torch.cat((PNES_data, TLE_data), axis=0)\n",
    "data = torch.cat((data, IGE_data), axis=0)\n",
    "data = torch.cat((data, Focal_data), axis=0).reshape(-1, 1, 19, 3000)\n",
    "\n",
    "\n",
    "labels = torch.cat((PNES_labels, TLE_labels))\n",
    "labels = torch.cat((labels, IGE_labels))\n",
    "labels = torch.cat((labels, Focal_labels))\n",
    "labels = F.one_hot(labels.to(torch.int64))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "test = MyDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, T, C, input_size, hidden_size, num_layers, spatial_num, dropout, pool):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.spatial_num = spatial_num\n",
    "        self.dropout = dropout\n",
    "        self.pool = pool\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.cell_count = self.T // self.input_size\n",
    "\n",
    "        self.fcn_in = (spatial_num * 8 * self.hidden_size)\n",
    "\n",
    "        self._lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "\n",
    "        self.lstm = nn.ModuleList([self._lstm for i in range(self.C)])\n",
    "\n",
    "        self.cnn_block = nn.Sequential(nn.Conv2d(1, self.spatial_num, (4, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "                                       nn.Conv2d(self.spatial_num, self.spatial_num * 2, (4, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num * 2),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "                                       nn.Conv2d(self.spatial_num * 2 , self.spatial_num * 4, (4, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num * 4),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "\n",
    "                                       nn.Conv2d(self.spatial_num * 4 , self.spatial_num * 6, (4, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num * 6),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "\n",
    "                                       nn.Conv2d(self.spatial_num * 6 , self.spatial_num * 8, (4, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num * 8),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "\n",
    "                                       nn.Conv2d(self.spatial_num * 8 , self.spatial_num * 8, (4, 1)),\n",
    "                                       nn.BatchNorm2d(self.spatial_num * 8),\n",
    "                                       nn.ELU(),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                        \n",
    "\n",
    "                                       nn.Dropout(self.dropout))\n",
    "\n",
    "        \n",
    "        self.fcn = nn.Sequential(nn.Linear(self.fcn_in, 64), \n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(64, 16),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(16, 4))\n",
    "\n",
    "        #self.fcn = nn.Linear(self.fcn_in, 4)\n",
    "        self.results = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, 19, 3000)\n",
    "        self.N = x.shape[0]\n",
    "        x = x.reshape(self.N, self.C, self.cell_count, self.input_size)\n",
    "        _x = None\n",
    "\n",
    "        for index, cell in enumerate(self.lstm):\n",
    "            cell_out, _ = cell(x[:, index, :, :], None)\n",
    "            last_layer_out = cell_out[:, -1, :]\n",
    "            \n",
    "            last_layer_out = last_layer_out.unsqueeze(0)\n",
    "            if _x is None:\n",
    "                _x = last_layer_out\n",
    "            else:\n",
    "                _x = torch.cat((_x, last_layer_out), dim=0)\n",
    "            \n",
    "\n",
    "        x = _x.permute(1, 0, 2).unsqueeze(1)\n",
    "\n",
    "        x = self.cnn_block(x)\n",
    "\n",
    "\n",
    "        x = x.reshape(self.N, -1)\n",
    "\n",
    "        x = self.fcn(x)\n",
    "        x = self.results(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([555, 4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net( T = 3000, C = 19, input_size = 60, hidden_size = 30, num_layers=1, spatial_num= 10, dropout=0.2, pool=1).to(device)\n",
    "model(X_test.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([479, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:44,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.17073170731707318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:01<00:32,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.3902439024390244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:01<00:29,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.1951219512195122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:02<00:26,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.4878048780487805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:03<00:25,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.3902439024390244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:03<00:24,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.6097560975609756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:04<00:23,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.6341463414634146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:04<00:22,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.5365853658536586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:05<00:21,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.6341463414634146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:05<00:21,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8292682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:06<00:20,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8536585365853658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:06<00:19,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8048780487804879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:07<00:19,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.926829268292683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:07<00:18,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8292682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:08<00:18,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.7073170731707317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:08<00:17,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8780487804878049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:09<00:17,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.9024390243902439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:09<00:16,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8292682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:10<00:16,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8292682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:10<00:15,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.926829268292683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:11<00:14,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8536585365853658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:11<00:14,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8780487804878049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:12<00:13,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.9024390243902439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:12<00:13,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.9024390243902439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:13<00:12,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.926829268292683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:13<00:12,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.9512195121951219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:14<00:12,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.9024390243902439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:14<00:12,  1.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2136\\3439959880.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 492\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\admin\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    b = torch.Tensor(479, 3000, 19)\n",
    "    a = torch.rand(479, 1, 19, 3000).cuda()\n",
    "\n",
    "    model = net( T = 3000, C = 19, input_size = 60, hidden_size = 30, num_layers=1, spatial_num= 10, dropout=0.2, pool=1).to(device)\n",
    "    print(model(a).shape)\n",
    "\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 50\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "    train_count, test_count = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_num = 0\n",
    "        batch_size = None\n",
    "\n",
    "        for index, data in enumerate(train_dataloader):\n",
    "            x, y = data\n",
    "            y = y.to(torch.float64)\n",
    "            batch_size = x.shape[0]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            __ = (torch.round(y_pred).to(torch.int64) == y)\n",
    "            preds = np.all(__.cpu().numpy(), axis=1)\n",
    "            correct_num += np.count_nonzero(preds)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        print(f\"Train Accuracy:{Accuracy(y_pred, y, y.shape[0])}\")\n",
    "\n",
    "        \n",
    "    #print(torch.round(model(X_test)))\n",
    "\n",
    "    #print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
