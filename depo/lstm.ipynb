{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"fmeasure\"]):\n",
    "    torch.cuda.empty_cache()\n",
    "    results = [] \n",
    "    predicted = []\n",
    "    batch_size=1\n",
    "\n",
    "    \n",
    "    for i in range(int((len(X)/batch_size))):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "            \n",
    "        inputs = Variable(X[s:e])\n",
    "        pred = model(inputs)\n",
    "            \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "            \n",
    "    predicted = torch.Tensor(predicted).view(-1, 1)\n",
    "\n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted))\n",
    "            recall = recall_score(Y, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.randn([14231, 9000, 18])\n",
    "Y_train = torch.ones([14231, 1])\n",
    "X_val = torch.randn([1581, 9000, 18])\n",
    "Y_val = torch.ones([1581, 1])\n",
    "X_test = torch.randn([10249, 9000, 18])\n",
    "Y_test = torch.ones([10249, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14231, 9000, 18])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class LSTM(nn.Module):  \n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # self.bn = nn.BatchNorm2d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        shape of x: (N, T, C)  N: batch_size, T: seq_len(time), C: input_size(channel)\n",
    "        \"\"\"\n",
    "        lstm_out, (h, c) = self.lstm(x, None)\n",
    "        # x = self.bn(lstm_out)\n",
    "        logits = self.fc(lstm_out[:, -1, :])\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return probas\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn((1, 9000, 18)).cuda()\n",
    "    model = LSTM(1, 18, 20, 20).cuda()\n",
    "    #summary(model.cuda(), (4, 1, 64, 256))\n",
    "    print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "\n",
      "Epoch  1\n",
      "\n",
      "Epoch  2\n"
     ]
    }
   ],
   "source": [
    "batch_size = 90\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(X_train[s:e].cuda())\n",
    "        labels = Variable(Y_train[s:e].cuda())\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(X_train.cuda()[5:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
