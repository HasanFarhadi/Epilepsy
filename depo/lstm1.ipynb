{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = str(1)\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"]= str(0)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likeliness(y_pred, y):\n",
    "    pred = torch.zeros([len(y_pred), y.shape[1]])\n",
    "    for idx, unit in enumerate(torch.argmax(y_pred, axis = 1)):\n",
    "        pred[idx, unit] = 1\n",
    "    return accuracy_score(pred.cpu(), y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.rand([42583, 1, 18, 300])\n",
    "y_train = torch.ones([42583, 4]) \n",
    "y_train[:, :3] = 0\n",
    "x_val = torch.rand([4731, 1, 18, 300])\n",
    "y_val = torch.ones([4731, 4]) \n",
    "y_val[:, :3] = 0\n",
    "x_test = torch.rand([11828, 1, 18, 300])\n",
    "y_test = torch.ones([11828, 4]) \n",
    "y_test[:, :3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_train, x_test, y_train, y_test, train=True):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.transforms = transforms.ToTensor()\n",
    "        self.x = x_train if train else x_test\n",
    "        self.y = y_train if train else y_test\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index, ...]\n",
    "        y = self.y[index, ...]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CNN_Spatial(nn.Module):\n",
    "    def __init__(self, num_classes, batch_size, T, C, input_size, hidden_size,\n",
    "                 num_layers, spatial_num=8, drop_out=0.5):\n",
    "        super(LSTM_CNN_Spatial, self).__init__()\n",
    "\n",
    "        self.N = batch_size\n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.pool = 4\n",
    "        self.seq_len = self.T // self.input_size\n",
    "        self.fc_in = spatial_num * self.hidden_size // self.pool\n",
    "        \n",
    "        self._lstm = nn.LSTM(self.input_size, self.hidden_size, \n",
    "                            self.num_layers, batch_first=True)\n",
    "        self.lstm = nn.ModuleList([self._lstm for i in range(self.C)])\n",
    "        \n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, spatial_num, (self.C, 1)),\n",
    "            nn.BatchNorm2d(spatial_num),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, self.pool)),\n",
    "            nn.Dropout(drop_out)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(self.fc_in , num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input shape of x: (N, 1, C, T)\n",
    "        self.N = x.shape[0]\n",
    "        x = x.reshape(self.N, self.C, self.seq_len, self.input_size)\n",
    "        _x = None\n",
    "        for index, lstm in enumerate(self.lstm):\n",
    "            lstm_out, _ = lstm(x[:, index, :, :], None)\n",
    "            tmp = lstm_out[:, -1, :]\n",
    "            tmp = tmp.unsqueeze(0)\n",
    "            if _x is None:\n",
    "                _x = tmp\n",
    "            else:\n",
    "                _x = torch.cat((_x, tmp), dim=0)\n",
    "        \n",
    "        # (C, N, H) ===> (N, 1, C, H)   H: hidden_size\n",
    "        x = _x.permute(1, 0, 2).unsqueeze(1)\n",
    "        x = self.block_1(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return probas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif __name__ == '__main__':\\n    # model test\\n    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\\n    x = torch.randn((4, 1, 18, 300))\\n    x = x.to(DEVICE)\\n    # num_classes = 4, batch_size = 4, T = 256, C = 64, input_size = 16, hidden_size = 16, num_layers = 2, spatial_num=8, drop_out=0.5\\n    model = LSTM_CNN_Spatial(2, 4, 300, 18, 15, 160, 20)\\n    model = model.to(DEVICE)\\n    y = model(x)\\n    print(y.data)\\n\""
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    # model test\n",
    "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.randn((4, 1, 18, 300))\n",
    "    x = x.to(DEVICE)\n",
    "    # num_classes = 4, batch_size = 4, T = 256, C = 64, input_size = 16, hidden_size = 16, num_layers = 2, spatial_num=8, drop_out=0.5\n",
    "    model = LSTM_CNN_Spatial(2, 4, 300, 18, 15, 160, 20)\n",
    "    model = model.to(DEVICE)\n",
    "    y = model(x)\n",
    "    print(y.data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data_loader, device, train_num, epochs, x_val, y_val, logged=False):\n",
    "    for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_num = 0\n",
    "        batch_size = None\n",
    "        for index, data in enumerate(data_loader):\n",
    "            x, y = data\n",
    "            batch_size = x.shape[0] if index == 0 else batch_size\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            _, pred = torch.max(y_pred, 1)\n",
    "            \n",
    "            correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += float(loss.item())\n",
    "            \n",
    "        batch_num = train_num // batch_size\n",
    "        _loss = running_loss / (batch_num + 1)\n",
    "        acc = correct_num / train_num * 100\n",
    "        if not logged:\n",
    "            print(f'Epoch {epoch+1}/{epochs}\\tTrain loss: {_loss:.4f}')\n",
    "        print(f\"val accuracy: {likeliness(model(x_val.cuda()), y_val.cuda())}\")\n",
    "        \n",
    "        print(model(x_train[0].cuda()))\n",
    "    \n",
    "    \n",
    "    if not logged:\n",
    "        print('Finish Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, data_loader, device, test_num, log, logged = False):\n",
    "    running_loss = 0.0\n",
    "    correct_num = 0\n",
    "    model.eval()\n",
    "    batch_size = None\n",
    "    for index, data in enumerate(data_loader):\n",
    "        x, y = data\n",
    "        batch_size = x.shape[0] if index == 0 else batch_size\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        _, pred = torch.max(y_pred, 1)\n",
    "        if sys.platform == 'linux':\n",
    "            correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n",
    "        else: \n",
    "            correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        running_loss += float(loss.item())\n",
    "    \n",
    "    batch_num = test_num // batch_size\n",
    "    _loss = running_loss / (batch_num + 1)\n",
    "    acc = correct_num / test_num * 100\n",
    "    print(f'Test loss: {_loss:.4f}\\tTest acc: {acc:.2f}%')\n",
    "    if logged:\n",
    "        log.append(f'{acc:.2f}\\t\\n')\n",
    "        with open('result.txt', 'a') as f:\n",
    "            f.writelines(log)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs, batch_size, input_size, hidden_size, num_layers, spatial_num, drop_out, x_val, y_val, logged=False):\n",
    "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print('DEVICE: ', DEVICE)\n",
    "    \n",
    "    group = 1\n",
    "    sorted_ = True\n",
    "    # sorted_ = False\n",
    "\n",
    "    # load data from '.npy' file\n",
    "    # x_train, x_test, y_train, y_test = load_group_eeg_data(date, group, sorted_=sorted_)\n",
    "    # x: (N, C, T)  N: trials  C: channels  T: times \n",
    "    train_num, test_num = x_train.shape[0], x_test.shape[0]\n",
    "    \n",
    "    # make dataset for train and test\n",
    "    train_data = MyDataset(x_train, x_test, y_train, y_test)\n",
    "    test_data = MyDataset(x_train, x_test, y_train, y_test, train=False)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    # model initiation\n",
    "    # model = LSTM(num_classes=2, input_size=64, hidden_size=256, num_layers=2)\n",
    "    \n",
    "    # model = LSTM_CNN(num_classes=2, channels=x_train.shape[1], input_size=input_size, hidden_size=hidden_size, \n",
    "    #                  num_layers=num_layers, spatial_num=spatial_num, drop_out=drop_out)\n",
    "    \n",
    "    # model = LSTM_CNN_Half(num_classes=2, batch_size=batch_size, T=x_train.shape[-1],\n",
    "    #                       C=x_train.shape[-2], input_size=input_size, hidden_size=hidden_size,\n",
    "    #                       num_layers=num_layers, spatial_num=spatial_num)\n",
    "    \n",
    "    model = LSTM_CNN_Spatial(num_classes=4, batch_size=batch_size, T=x_train.shape[-1],\n",
    "                          C=x_train.shape[-2], input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, spatial_num=spatial_num)\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "    log = []\n",
    "    if logged:\n",
    "        log.append(f'{epochs}\\t{batch_size}\\t{input_size}\\t{hidden_size}\\t'\n",
    "                   f'{num_layers}\\t{spatial_num}\\t{drop_out}\\t')\n",
    "    train(model, criterion, optimizer, train_loader, DEVICE,train_num, epochs, x_val, y_val, logged=False)\n",
    "    test(model, criterion, test_loader, DEVICE, test_num, log, logged = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8944\\3451856606.py:15: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n",
      " 25%|██▌       | 1/4 [00:02<00:08,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\tTrain loss: 1.2890\n",
      "val accuracy: 0.9141830479813993\n",
      "tensor([[0.1605, 0.1189, 0.2574, 0.4632]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8944\\3451856606.py:15: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n",
      " 50%|█████     | 2/4 [00:05<00:05,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\tTrain loss: 1.1690\n",
      "val accuracy: 0.9847812301838935\n",
      "tensor([[0.0658, 0.2223, 0.2052, 0.5067]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8944\\3451856606.py:15: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\tTrain loss: 1.0348\n",
      "val accuracy: 0.9985203973789897\n",
      "tensor([[0.0416, 0.0946, 0.1572, 0.7066]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8944\\3451856606.py:15: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\tTrain loss: 0.9265\n",
      "val accuracy: 0.9995772563939971\n",
      "tensor([[0.0544, 0.0295, 0.1059, 0.8102]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.57s/it]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8944\\1781226366.py:16: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  correct_num += np.sum(pred.cpu().numpy() == y.cpu().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Training!\n",
      "Test loss: 0.8679\tTest acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "batch_size = 4096\n",
    "input_size = 15\n",
    "hidden_size = 16\n",
    "num_layers = 4\n",
    "spatial_num = 8\n",
    "drop_out = 0.5\n",
    "logged = False\n",
    "model = main(epochs, batch_size, input_size, hidden_size, num_layers, spatial_num, drop_out, x_val, y_val, logged=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
